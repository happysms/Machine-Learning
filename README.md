
# Machine-Learning

## 단층 퍼셉트론(Single-layer Perceptron): 입력 벡터를 두 부류로 구분하는 선형분류기

> 임계치(threshold) : 어떠한 값이 활성화되기 위한 최소값
> 
> 가중치(weight) : 퍼셉트론의 학습 목표는 학습 벡터를 **두 부류로 선형 분류**하기 위한 선형 경계를 찾는 것이다. 가중치는 이러한 선형 경계의 **방향성 또는 형태**를 나타낸다. 가중치의 값이 클수록 해당 입력값은 중요하다.
> 
> 바이어스(bias): **선형 경계의 절편**을 나타내는 값으로써, 직선의 경우는 y절편을 나타낸다. 
> 
> net값: **입력값과 가중치의 곱**을 모두 합한 값으로써, 기하학적으로 해석하면 **선형 경계의 방정식**과 같다. 
> 
> 활성함수(activation function): 뉴런에서 계산된 net값이 **임계치보다 크면 1**을 출력하고, **임계치보다 작으면 0**을 출력하는 함수이다. 이 정의는 단층 퍼셉트론에서만 유효하며, 다층 퍼셉트론에서는 다른 형태의 활성함수를 이용한다. 

> 뉴런(neuron): 인공신경망을 구성하는 가장 작은 요소로써, net값이 임계치보다 크면 활성화되면서 1을 출력하고, 반대의 경우 비활성화되면서 0을 출력한다. 

### 알고리즘 구조 : 단층 퍼셉트론 입력층(input layer)과 출력층(output layer)으로 구성된다. 입력층은 학습 벡터 또는 입력 벡터가 입력되는 계층으로써, 입력된 데이터는 출력층 뉴런으로 전달되어 활성함수에 따라 값이 출력된다. 출력층은 퍼셉트론 설계 시 임의의 n개의 뉴런으로 구성할 수 있다.
>1) 가중치와 바이어스 가중치를 -0.5와 0.5 사이의 임의의 값으로, 바이어스 입력값을 임의의 값으로 초기화

>2) 하나의 학습 벡터에 대한 출력층 뉴런의 net값을 계산

>3) 활성함수를 통해 계산된 net값으로부터 뉴런의 실제 출력값을 계산

>4-1) 뉴런의 출력값과 목표값의 차이가 허용 오차보다 작으면 5로 이동

>4-2) 뉴런의 출력값과 목표값의 차이가 허용 오차보다 크면 학습을 진행

>5-1) 현재 학습 벡터가 마지막 학습 벡터가 아니면, 현재 학습 벡터를 다음 학습 벡터로 설정하고 2로 이동하여 반복

>5-2-1) 현재 학습 벡터가 마지막 학습 벡터이고, 모든 학습 벡터에 대해 출력값과 목표값이 허용 오차보다 작으면 알고리즘 종료

>5-2-2) 현재 학습 벡터가 마지막 학습 벡터이지만 출력값과 목표값이 허용 오차보다 큰 학습 벡터가 존재하면, 현재 학습 벡터를 처음 학습 벡터로 설정하고 2로 이동하여 반복

### 활성함수의 정의
-> 활성함수는 **net값이 임계치보다 크면 뉴런의 출력값을 활성화**하고, 그렇지 않으면 뉴런의 출력값을 비활성화하는 함수이다. 퍼셉트론에서 사용하는 가장 기본적인 활성함수는 계단 함수(step function)를 이용한다!
[image](https://user-images.githubusercontent.com/70648382/112706256-7581df80-8ee6-11eb-9cea-16322c897840.png)


# 용어 정리
> epoch : 한 번의 epoch는 인공 신경망에서 전체 데이터 셋에 대해 forward pass/ backward pass 과정을 거친 것을 말한다. 즉 , 전체 데이터 셋에 대해 한 번 학습을 완료한 상태이다. 

> 역전파 알고리즘: 파라미터를 사용하여 입력부터 출력까지의 각 계층의 weight를 계산하는 과정을 거치는 forward pass, backward pass로 나뉜다. 이 전체 데이터 셋에 대해 해당 과정(forward pass + backward pass)이 완료되면 한 번의 epoch가 수행된 것이다. 

<p align="center"><img width="231" alt="스크린샷 2021-03-19 오후 7 17 02" src="https://user-images.githubusercontent.com/70648382/116772986-a3ca8000-aa8d-11eb-94bb-771302e6b000.png">

